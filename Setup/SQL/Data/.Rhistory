typeof(a)
a + 1
a + 4
a + 4L
a + 4.3
typeof(a + 4.3)
typeof(a + 4L)
typeof(a + 4)
#--Vectors--
v1 = c(1,2,3)
v1
#--Vectors--
v1 = c(1,'2',3)
v1
v1
# --Vectors--
v1 = c(1,2,3)
v1
v2 = c(1,'2',3)
v2
typeof(v1)
typeof(v2)
type(v2)
v3 = c(1,TRUE,3)
V3
v3
length(v1)
v4 <- c(v1, 5)
v4
v1[0]
v1[1]
v1
v1[3]
v1[4]
v1[5]
v1[1,2]
v1[c(1,2)]
#filter
v1[1] #index starts from 1
v1 <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)
v1[3,5] # error
v1[c(3,5)]
v1 <- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l')
v1[3,5] # error
v1[c(3,5)]
1:10
v1[3:5]
v1[c(3:5, 7)]
1:10 #range
#filter
v1[1] #index starts from 1
v1 <- c('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l')
v1[3,5] # error
v1[c(3,5)]
v1[3:5] # all end points included
v1[c(3:5, 7)]
seq(1,10,0.1) # sequence
?seq
?seq
#NA
x <- c("a", NA, "c", "d", "e")
is.na(x)
x[is.na(x)]
x[!is.na(x)]
is.na(x)
!is.na(x)
x[!is.na(x)]
c(1,2,3, c(4,5,6))
c(c(1,2,3), c(4,5,6))
[1,2,4]
#List
a_list <- list(1,2,3)
a_list
#List
a_list <- list(1,'a',3)
a_list
#List
a_list <- list(1,'a',TRUE)
a_list
a_list[[1]]
a_list[[1]][1]
typeof(a_list[[1]])
typeof(a_list[[1]][1])
typeof(a_list[[1]])
a_list[1]
a_list[[1]]
typeof(a_list[1])
typeof(a_list[[1]])
typeof(a_list[[1]])
typeof(a_list[1])
a_list[[1]]
a_list[1]
length(a_list[1])
a_list[2]
a_list <- list(1,'a',TRUE, c(1,2,3))
a_list
a_list[[4]][2]
a_list <- list(1,'a',TRUE, 1:100)
a_list
typeof(a_list[1]) #list
typeof(a_list[[1]]) #double
a_list <- list(1,'a',TRUE, 1:100)
a_list[[4]][2]
b_list = list(1,2, list(3,4, c(5,6)))
b_list
b_list[[3]][[1]]
a_list <- list(1,'a',TRUE, 1:100)
a_list
a_list[[2:3]]
a_list[[1:2]]
a_list[[1]]
a_list[[2]]
a_list[1:3]
a_list[1:2]
plot(cars)
a = 1
a
a = 1
a = 3
a
reticulate::repl_python()
View(mtcars)
system("java -version")
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
library(rJava)
library(rJava)
require(xlsx)
library(rJava)
library(rJava)
Sys.setenv(JAVA_HOME='/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home')
require(xlsx)
install.packages("psych")
# Q1
N = seq(0,0.5,length.out = 100)
P = seq(155.1,200, length.out = 100)
payoff_list = c()
N_list = c()
P_list = c()
for(n in N)
{
for(p in P)
{
if((11.4*n + 0.5*p) < 83.25 )
{
payoff = n*(p-155.1)
payoff_list = c(payoff_list, payoff)
N_list = c(N_list, n)
P_list = c(P_list, p)
}
}
}
payoff_list[which(payoff_list == max(payoff_list))]
N_list[which(payoff_list == max(payoff_list))]
P_list[which(payoff_list == max(payoff_list))]
library(readr)
GDPC1 <- read_csv("~/Downloads/GDPC1.csv")
typeof(GDPC1)
GDP <- as.data.frame(GDPC1)
head(GDPC1,3)
library(readr)
GDPC1 <- read_csv("~/Downloads/GDPC1.csv")
GDP <- as.data.frame(GDPC1)
head(GDPC1,3)
GDP$growth <- c(NA, diff(log(GDPC1$GDPC1)) * 100)
GDP <- na.omit(GDP)
head(GDP,3)
2027.639/2023.452
2023.452/2027.639
library(readr)
GDPC1 <- read_csv("~/Downloads/GDPC1.csv")
GDP <- as.data.frame(GDPC1)
head(GDPC1,3)
GDP$growth <- c(NA, diff(log(GDPC1$GDPC1)) * 100)
GDP <- na.omit(GDP)
head(GDP,3)
dim(GDP)
( 2023.452 - 2027.639)/2027.639
head(GDP,3)
dim(GDP)
arma_1_1 <- arima(x = GDP.train$growth, order = c(1, 0, 1))
arma_1_1_predict <- predict( arma_1_1, n.ahead = 10, se.fit = FALSE)
arma_1_1_MSE <- mean( (arma_1_1_predict - GDP.test$growth) ^ 2 )
GDP.train <- GDP[1:269, ]
GDP.test <- GDP[270:279, ]
arma_1_1 <- arima(x = GDP.train$growth, order = c(1, 0, 1))
arma_1_1_predict <- predict( arma_1_1, n.ahead = 10, se.fit = FALSE)
arma_1_1_MSE <- mean( (arma_1_1_predict - GDP.test$growth) ^ 2 )
round(arma_1_1_MSE, 4)
# ARMA Example
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, 0))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(0, 0, i))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ensemble <- rbind( ensemble, temp_predict)
}
for (i in 1:2) {
for(j in 1:2 ){
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, j))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
}
ensemble_predict <- colMeans(ensemble)
ensemble_MSE <- mean( (ensemble_predict - GDP.test$growth) ^ 2 )
round(ensemble_MSE, 4)
sample.int(200,1)
sample.int(200,1)
sample.int(200,1)
sample.int(200,1)
sample.int(200,1)
sample.int(200,1)
# random forest
library(tree)
library(ISLR)
High <- ifelse(Carseats$Sales <= 8, "No", "Yes")
Carseats <- data.frame(Carseats, High)
tree.carseats <- tree(High ~. -Sales, Carseats)
head(Carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = .5)
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train, ]
High.test <- High[-train]
tree.carseats <- tree(High ~. -Sales, Carseats, subset=train)
tree.pred <- predict(tree.carseats, Carseats.test, type="class")
table(tree.pred, High.test)
(104+50)/200
set.seed(3)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
library(readr)
GDPC1 <- read_csv("~/Downloads/GDPC1.csv")
GDP <- as.data.frame(GDPC1)
head(GDPC1,3)
GDP$growth <- c(NA, diff(log(GDPC1$GDPC1)) * 100)
GDP <- na.omit(GDP)
head(GDP,3)
dim(GDP)
GDP.train <- GDP[1:269, ]
GDP.test <- GDP[270:279, ]
arma_1_1 <- arima(x = GDP.train$growth, order = c(1, 0, 1))
arma_1_1_predict <- predict( arma_1_1, n.ahead = 10, se.fit = FALSE)
arma_1_1_MSE <- mean( (arma_1_1_predict - GDP.test$growth) ^ 2 )
round(arma_1_1_MSE, 4)
# ARMA Example
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, 0))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(0, 0, i))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ensemble <- rbind( ensemble, temp_predict)
}
for (i in 1:2) {
for(j in 1:2 ){
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, j))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
}
# Ensemble
ensemble_predict <- colMeans(ensemble)
ensemble_MSE <- mean( (ensemble_predict - GDP.test$growth) ^ 2 )
round(ensemble_MSE, 4)
# random forest
library(tree)
library(ISLR)
High <- ifelse(Carseats$Sales <= 8, "No", "Yes")
Carseats <- data.frame(Carseats, High)
tree.carseats <- tree(High ~. -Sales, Carseats)
head(Carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = .5)
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train, ]
High.test <- High[-train]
tree.carseats <- tree(High ~. -Sales, Carseats, subset=train)
tree.pred <- predict(tree.carseats, Carseats.test, type="class")
table(tree.pred, High.test)
set.seed(3)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
par(mfrow = c(1, 2))
plot(cv.carseats$size, cv.carseats$dev,type = "b")
plot(cv.carseats$k, cv.carseats$dev,type = "b")
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
par(mfrow = c(1, 1))
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
set.seed(3)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
par(mfrow = c(1, 2))
plot(cv.carseats$size, cv.carseats$dev,type = "b")
plot(cv.carseats$k, cv.carseats$dev,type = "b")
?cv.tree
tree.pred <- predict(prune.carseats,Carseats.test,type = "class")
table(tree.pred, High.test)
library(randomForest)
## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.
library(MASS)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston) / 2)
rf.boston <- randomForest(medv~., data = Boston, subset = train, mtry = 6, importance = TRUE)
importance(rf.boston)
boston.test <- Boston[-train, "medv"]
yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
## [1] 11.53109
plot(yhat.rf, boston.test)
abline(0,1)
par(mfrow=c(1,1))
boston.test <- Boston[-train, "medv"]
yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
## [1] 11.53109
plot(yhat.rf, boston.test)
abline(0,1)
boston.test
library(gbm)
library(MASS)
head(Boston,2)
install.packages("ggbm")
install.packages("gbm")
library(gbm)
library(MASS)
head(Boston,2)
library(gbm)
install.packages("gbm")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("gbm")
library(gbm)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
library(MASS)
head(Boston,2)
set.seed(1)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
summary(boost.boston)
set.seed(1)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
summary(boost.boston)
yhat.boost <- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000)
mean((yhat.boost-boston.test)^2)
yhat.boost <- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000)
mean((yhat.boost-boston.test)^2)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
yhat.boost <- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000)
mean((yhat.boost - boston.test)^2)
library(readr)
GDPC1 <- read_csv("~/Downloads/GDPC1.csv")
GDP <- as.data.frame(GDPC1)
head(GDPC1,3)
GDP$growth <- c(NA, diff(log(GDPC1$GDPC1)) * 100)
GDP <- na.omit(GDP)
head(GDP,3)
dim(GDP)
GDP.train <- GDP[1:269, ]
GDP.test <- GDP[270:279, ]
arma_1_1 <- arima(x = GDP.train$growth, order = c(1, 0, 1))
arma_1_1_predict <- predict( arma_1_1, n.ahead = 10, se.fit = FALSE)
arma_1_1_MSE <- mean( (arma_1_1_predict - GDP.test$growth) ^ 2 )
round(arma_1_1_MSE, 4)
# ARMA Example
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, 0))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
for (i in 1:15) {
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(0, 0, i))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ensemble <- rbind( ensemble, temp_predict)
}
for (i in 1:2) {
for(j in 1:2 ){
data <- GDP.train[sample.int(200,1):269,]$growth
temp <- arima(x = data, order = c(i, 0, j))
temp_predict <- predict( temp, n.ahead = 10, se.fit = FALSE)
ifelse ( exists("ensemble"), ensemble <- rbind( ensemble, temp_predict), ensemble <- temp_predict )
}
}
# Ensemble
ensemble_predict <- colMeans(ensemble)
ensemble_MSE <- mean( (ensemble_predict - GDP.test$growth) ^ 2 )
round(ensemble_MSE, 4)
# random forest
library(tree)
library(ISLR)
High <- ifelse(Carseats$Sales <= 8, "No", "Yes")
Carseats <- data.frame(Carseats, High)
tree.carseats <- tree(High ~. -Sales, Carseats)
head(Carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0, cex = .5)
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train, ]
High.test <- High[-train]
tree.carseats <- tree(High ~. -Sales, Carseats, subset=train)
tree.pred <- predict(tree.carseats, Carseats.test, type="class")
table(tree.pred, High.test)
set.seed(3)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
par(mfrow = c(1, 2))
plot(cv.carseats$size, cv.carseats$dev,type = "b")
plot(cv.carseats$k, cv.carseats$dev,type = "b")
par(mfrow = c(1, 1))
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0, cex = 0.5)
tree.pred <- predict(prune.carseats,Carseats.test,type = "class")
table(tree.pred, High.test)
library(randomForest)
## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.
library(MASS)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston) / 2)
rf.boston <- randomForest(medv~., data = Boston, subset = train, mtry = 6, importance = TRUE)
importance(rf.boston)
par(mfrow=c(1,1))
boston.test <- Boston[-train, "medv"]
yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
## [1] 11.53109
plot(yhat.rf, boston.test)
abline(0,1)
library(gbm)
library(MASS)
head(Boston,2)
set.seed(1)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
summary(boost.boston)
yhat.boost <- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000)
mean((yhat.boost-boston.test)^2)
boost.boston <- gbm(medv ~., data = Boston[train, ], distribution = "gaussian", n.trees = 5000, interaction.depth = 3)
yhat.boost <- predict(boost.boston, newdata = Boston[-train, ], n.trees = 5000)
mean((yhat.boost - boston.test)^2)
x = seq(0,100, length.out = 10000)
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,10)
plot(x,y)
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,100)
plot(x,y)
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,50)
plot(x,y)
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,50)
plot(x,y)
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,50)
plot(x,y)
x = seq(0,100, length.out = 10000)
y = -2*x + rnorm(10000, 0,50)
plot(x,y)
setwd("~/Documents/Hadoop/OnlineLearning/Setup/SQL/Data")
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,50)
plot(x,y)
df1 = data.frame(x = x, y = y)
rows <- sample(nrow(df1))
df1 = df1[rows,]
write.csv(df1, 'regime1.csv')
x = seq(0,100, length.out = 10000)
y = -2*x + rnorm(10000, 0,50)
plot(x,y)
df2 = data.frame(x = x, y = y)
rows <- sample(nrow(df2))
df2 = df2[rows,]
write.csv('regime2.csv')
x = seq(0,100, length.out = 10000)
y = 2*x + rnorm(10000, 0,50)
plot(x,y)
df1 = data.frame(x = x, y = y)
rows <- sample(nrow(df1))
df1 = df1[rows,]
write.csv(df1, 'regime1.csv', row.names = F)
x = seq(0,100, length.out = 10000)
y = -2*x + rnorm(10000, 0,50)
plot(x,y)
df2 = data.frame(x = x, y = y)
rows <- sample(nrow(df2))
df2 = df2[rows,]
write.csv(df2, 'regime2.csv', row.names = F)
